#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Plot both the responses to a sung melody and the same melody as generated by 
MIDI.
"""

import numpy as np
from detectorbank import DetectorBank
import soundfile as sf
import matplotlib.pyplot as plt
import seaborn as sns
import os.path


def getResponses(sr, audio, note_range):
    
    method = DetectorBank.runge_kutta #central_difference# 
    f_norm = DetectorBank.freq_unnormalized
    a_norm = DetectorBank.amp_normalized
    d = 0.0001
    gain = 50
    
    f = np.array([440*2**(k/12) for k in note_range])
    
    bandwidth = np.zeros(len(f))
    det_char = np.array(list(zip(f, bandwidth)))
    
    det = DetectorBank(sr, audio.astype(np.float32), 4, det_char, 
                       method|f_norm|a_norm, d, gain)
    
    z = np.zeros((len(f),len(audio)), dtype=np.complex128) 
    r = np.zeros(z.shape)

    det.getZ(z)
    det.absZ(r, z)
    
    return r
        

    
def plotResponses(sr, audio, rng, span=None):
    
    sns.set_style('whitegrid')
    
    if span is None:
        t0, t1 = 0, len(audio)
    else:
        t0, t1 = (int(t*sr) for t in span)
    
    r = getResponses(sr, audio, rng)
    
    c = ['chocolate', 'black', 'blue', 'deeppink', 'cyan', 'purple', 'gold',
         'dodgerblue', 'red', 'limegreen', 'lightslategrey', 'magenta', 
         'darkorange', 'darkgreen',  'skyblue', 'firebrick']
    
    t = np.linspace(0, r.shape[1]/sr, r.shape[1])
        
    for k in range(r.shape[0]):
        plt.plot(t[t0:t1], r[k][t0:t1], c[k]) # c[(k+c_offset) % len(scale)])
        
    plt.xlabel('Times (s)')
    plt.ylabel('|z|', rotation='horizontal', labelpad=10)
    plt.grid(True)
    plt.show()
    plt.close()
    
    # the following data can be used to construct the legend
    scale = ['c', 'c#', 'd', 'd#', 'e', 'f', 'f#', 'g', 'g#', 'a', 'a#', 'b']
    scale = ['C', 'D'+'\u266D', 'D', 'E'+'\u266D', 'E', 'F', 'G'+'\u266D', 'G', 
             'A'+'\u266D', 'A', 'B'+'\u266D', 'B']
    offset = (scale.index('A') + rng[0]) % len(scale)
    octnum = [((k+45)//12)+1 for k in rng]
    labNotes = ['{}{}'.format(scale[(i+offset) % len(scale)], octnum[i])
                for i in range(len(octnum))]
    
    labHz = ['{:.0f} Hz'.format(440*2**(k/12)) for k in rng]
    
    labels = ['{}, {}'.format(labHz[i], labNotes[i]) for i in range(len(labHz))]


if __name__ == '__main__':
    
    datapath = os.path.join('data')
    
    before_dict = {'name':'Before All Things', 'fname':'bfr48'}
    
    midi_dict = {'name':'Before All Things (MIDI rendering)', 
                 'fname':'bfr_midi48'}
    
    dicts = [before_dict, midi_dict]
    
    span = None #(1.8, 5.1)
    
    for d in dicts:
        
        fname = d['fname'] + '.wav'
        file = os.path.join(datapath, fname)
        
        audio, sr = sf.read(file)
        
        rng = range(-4, 12)
        
        plotResponses(sr, audio, rng, span)

        
        
